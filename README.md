# ğŸš€ IntroduÃ§Ã£o ao Databricks com Apache Spark, Delta Lake e MLflow

## ğŸ“š HistÃ³rico

O **Databricks** foi fundado por criadores do **Apache Spark**, como uma plataforma unificada para engenharia, ciÃªncia de dados e machine learning na nuvem. Ele integra tecnologias como:

- **Apache Spark** â€“ Processamento distribuÃ­do de dados em larga escala.
- **Delta Lake** â€“ Armazenamento transacional para data lakes (ACID, versionamento, schema enforcement).
- **MLflow** â€“ Gerenciamento de ciclos de vida de modelos de machine learning (experimentos, deployment, tracking).

---

## ğŸ“ Criando uma Conta Gratuita no Databricks (Community Edition)

A Community Edition Ã© ideal para fins de estudo e testes.

1. Acesse: [https://community.cloud.databricks.com](https://community.cloud.databricks.com)
2. Clique em **"Sign Up"** e preencha os dados.
3. Confirme o e-mail e acesse o ambiente gratuito com recursos limitados.

---

## ğŸ Iniciando um Projeto

1. ApÃ³s o login, vÃ¡ para o menu esquerdo e clique em:
   - **Workspace > Users > SeuNome**
   - Crie uma pasta: `meu_projeto`
   - Crie um **Notebook** dentro da pasta (ex: `analise_dados`)

2. Escolha o tipo de linguagem:
   - `Python`, `SQL`, `Scala` ou `R`

---

## âš™ï¸ Provisionando o Databricks: Criando um Cluster

1. VÃ¡ atÃ© a aba **Compute** e clique em **Create Cluster**
2. DÃª um nome ao cluster (ex: `cluster-estudo`)
3. Mantenha o **Databricks Runtime** padrÃ£o (recomenda-se versÃ£o com ML)
4. Clique em **Create Cluster**

O cluster pode levar alguns minutos para iniciar.

---

## ğŸ” Usando Spark para Analisar Dados

No notebook criado, conecte-se ao cluster e use Spark para ler e analisar dados. 

---

## âœ… ConclusÃ£o
Com o Databricks Community Edition, Ã© possÃ­vel experimentar na prÃ¡tica o ecossistema de Big Data e IA, usando Apache Spark para anÃ¡lise distribuÃ­da, Delta Lake para confiabilidade e MLflow para rastreamento de modelos.
